{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle-titanic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtVXZ45yv0QzU841qbrWr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szymros/kaggle-titanic/blob/main/kaggle_titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AJzZGjQ6sjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffad458e-0175-40dd-f308-a6a104b59ad7"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "data = pd.read_csv('train.csv')\n",
        "data.pop(item='Name')\n",
        "data.pop(item='Ticket')\n",
        "data.pop(item='PassengerId')\n",
        "y_train = data.pop(item='Survived')\n",
        "s = pd.get_dummies(data['Sex'])\n",
        "pclass = pd.get_dummies(data['Pclass'], prefix=\"class\")\n",
        "data.pop(item='Sex')\n",
        "data.pop(item='Pclass')\n",
        "data.pop(item='Embarked')\n",
        "data = data.join(s)\n",
        "data = data.join(pclass)\n",
        "data.pop(item='Cabin')\n",
        "data['Age'].fillna(0, inplace=True)\n",
        "X = data.values\n",
        "X[:,0] = tf.keras.utils.normalize(X[:,0])\n",
        "X[:,3] = tf.keras.utils.normalize(X[:,3])\n",
        "X.shape, data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((891, 9),\n",
              "       Age  SibSp  Parch     Fare  female  male  class_1  class_2  class_3\n",
              " 0    22.0      1      0   7.2500       0     1        0        0        1\n",
              " 1    38.0      1      0  71.2833       1     0        1        0        0\n",
              " 2    26.0      0      0   7.9250       1     0        0        0        1\n",
              " 3    35.0      1      0  53.1000       1     0        1        0        0\n",
              " 4    35.0      0      0   8.0500       0     1        0        0        1\n",
              " ..    ...    ...    ...      ...     ...   ...      ...      ...      ...\n",
              " 886  27.0      0      0  13.0000       0     1        0        1        0\n",
              " 887  19.0      0      0  30.0000       1     0        1        0        0\n",
              " 888   0.0      1      2  23.4500       1     0        0        0        1\n",
              " 889  26.0      0      0  30.0000       0     1        1        0        0\n",
              " 890  32.0      0      0   7.7500       0     1        0        0        1\n",
              " \n",
              " [891 rows x 9 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5rLhjWla_He1",
        "outputId": "d35cb8ec-e473-4910-8273-5694c11ca9c6"
      },
      "source": [
        "pd.DataFrame(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.024906</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.043020</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040344</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.029435</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004485</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.039624</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030053</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.039624</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0.030567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007358</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>0.021510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016979</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.013272</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>0.029435</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0.036227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0    1    2         3    4    5    6    7    8\n",
              "0    0.024906  1.0  0.0  0.004103  0.0  1.0  0.0  0.0  1.0\n",
              "1    0.043020  1.0  0.0  0.040344  1.0  0.0  1.0  0.0  0.0\n",
              "2    0.029435  0.0  0.0  0.004485  1.0  0.0  0.0  0.0  1.0\n",
              "3    0.039624  1.0  0.0  0.030053  1.0  0.0  1.0  0.0  0.0\n",
              "4    0.039624  0.0  0.0  0.004556  0.0  1.0  0.0  0.0  1.0\n",
              "..        ...  ...  ...       ...  ...  ...  ...  ...  ...\n",
              "886  0.030567  0.0  0.0  0.007358  0.0  1.0  0.0  1.0  0.0\n",
              "887  0.021510  0.0  0.0  0.016979  1.0  0.0  1.0  0.0  0.0\n",
              "888  0.000000  1.0  2.0  0.013272  1.0  0.0  0.0  0.0  1.0\n",
              "889  0.029435  0.0  0.0  0.016979  0.0  1.0  1.0  0.0  0.0\n",
              "890  0.036227  0.0  0.0  0.004386  0.0  1.0  0.0  0.0  1.0\n",
              "\n",
              "[891 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZNewdOoIPLG",
        "outputId": "517c4419-4191-440f-94ef-11486669db5c"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(60, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(60, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "history = model.fit(X, y_train, epochs=200, batch_size=X.size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.7000 - accuracy: 0.6150\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6896 - accuracy: 0.6195\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6797 - accuracy: 0.6274\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6703 - accuracy: 0.6308\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6615 - accuracy: 0.6330\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6532 - accuracy: 0.6319\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6319\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6384 - accuracy: 0.6330\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6316 - accuracy: 0.6330\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6251 - accuracy: 0.6375\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6189 - accuracy: 0.6386\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6129 - accuracy: 0.6386\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6070 - accuracy: 0.6386\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6013 - accuracy: 0.6386\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5959 - accuracy: 0.6397\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5907 - accuracy: 0.6476\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 0.6543\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5806 - accuracy: 0.6566\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5758 - accuracy: 0.7015\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5711 - accuracy: 0.7015\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5665 - accuracy: 0.6992\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.6970\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7037\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5531 - accuracy: 0.7059\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5487 - accuracy: 0.7385\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5443 - accuracy: 0.7419\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5400 - accuracy: 0.7407\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7430\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5316 - accuracy: 0.7464\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5276 - accuracy: 0.7441\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5237 - accuracy: 0.7452\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5200 - accuracy: 0.7542\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5163 - accuracy: 0.7800\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5128 - accuracy: 0.7800\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7811\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7811\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.7811\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7811\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.7789\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4923 - accuracy: 0.7789\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4891 - accuracy: 0.7789\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7789\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7800\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7924\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7980\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4745 - accuracy: 0.7980\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7980\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.7980\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7980\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.7980\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7980\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4607 - accuracy: 0.7980\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.8002\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4571 - accuracy: 0.8025\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4554 - accuracy: 0.8025\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.8036\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.8036\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.8036\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8036\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.8025\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.8047\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.8047\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.8047\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8047\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4432 - accuracy: 0.8047\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4424 - accuracy: 0.8047\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4415 - accuracy: 0.8047\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4408 - accuracy: 0.8070\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4400 - accuracy: 0.8070\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4393 - accuracy: 0.8081\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4386 - accuracy: 0.8081\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4379 - accuracy: 0.8081\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4372 - accuracy: 0.8081\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4366 - accuracy: 0.8081\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.8092\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4354 - accuracy: 0.8092\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4348 - accuracy: 0.8092\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4343 - accuracy: 0.8092\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4337 - accuracy: 0.8092\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4332 - accuracy: 0.8092\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4327 - accuracy: 0.8081\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.8070\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4318 - accuracy: 0.8070\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4314 - accuracy: 0.8070\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.8070\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.8070\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4301 - accuracy: 0.8092\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4298 - accuracy: 0.8092\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4294 - accuracy: 0.8092\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.8070\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4287 - accuracy: 0.8070\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4284 - accuracy: 0.8058\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4281 - accuracy: 0.8058\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8058\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4275 - accuracy: 0.8058\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.8058\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.8058\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.8058\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4264 - accuracy: 0.8058\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4261 - accuracy: 0.8058\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8058\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4256 - accuracy: 0.8058\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8058\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.8058\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4250 - accuracy: 0.8058\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4247 - accuracy: 0.8058\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4245 - accuracy: 0.8058\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4243 - accuracy: 0.8058\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8058\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4239 - accuracy: 0.8058\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8058\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.8070\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8070\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8070\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.8070\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8070\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8070\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8070\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8070\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.8081\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8081\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8092\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8092\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8092\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8092\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4211 - accuracy: 0.8092\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.8092\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.8092\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8092\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8103\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4204 - accuracy: 0.8103\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8103\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8103\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8103\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8092\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8092\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8081\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.8081\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8081\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8070\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8058\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8058\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4189 - accuracy: 0.8058\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4188 - accuracy: 0.8058\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8058\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4185 - accuracy: 0.8070\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4184 - accuracy: 0.8070\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4183 - accuracy: 0.8070\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4182 - accuracy: 0.8070\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.8070\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8070\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8070\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4178 - accuracy: 0.8058\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4177 - accuracy: 0.8058\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4176 - accuracy: 0.8058\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8070\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4174 - accuracy: 0.8070\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.8070\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4171 - accuracy: 0.8070\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4170 - accuracy: 0.8070\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4169 - accuracy: 0.8070\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4168 - accuracy: 0.8070\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8070\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8070\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.8070\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8070\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.8081\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4162 - accuracy: 0.8081\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8081\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8081\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8081\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8081\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8081\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8092\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8081\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8081\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8081\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8081\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.8070\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8070\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8070\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.8070\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8070\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4149 - accuracy: 0.8070\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8081\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8081\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8081\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4145 - accuracy: 0.8081\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.8058\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8058\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8058\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8058\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4142 - accuracy: 0.8070\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8070\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4140 - accuracy: 0.8070\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8070\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8070\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8070\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4137 - accuracy: 0.8070\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-Q5gTkr-Kd11",
        "outputId": "c1267527-e71c-4ac6-8977-16c27ac97bc4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "pd.DataFrame(history.history).plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f48c4953e90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwS_Oagiakoz",
        "outputId": "db486068-dfd6-444d-87a3-841cef97daca"
      },
      "source": [
        "data2 = pd.read_csv('test.csv')\n",
        "data2.pop(item='Name')\n",
        "data2.pop(item='Ticket')\n",
        "data2.pop(item='PassengerId')\n",
        "s = pd.get_dummies(data2['Sex'])\n",
        "pclass = pd.get_dummies(data2['Pclass'], prefix=\"class\")\n",
        "data2.pop(item='Sex')\n",
        "data2.pop(item='Pclass')\n",
        "data2.pop(item='Embarked')\n",
        "data2 = data2.join(s)\n",
        "data2 = data2.join(pclass)\n",
        "data2.pop(item='Cabin')\n",
        "data2['Age'].fillna(0, inplace=True)\n",
        "data2['Fare'].fillna(0, inplace=True)\n",
        "X_test = data2.values\n",
        "X_test[:,0] = tf.keras.utils.normalize(X_test[:,0])\n",
        "X_test[:,3] = tf.keras.utils.normalize(X_test[:,3])\n",
        "X_test.shape, data2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((418, 9),\n",
              "       Age  SibSp  Parch      Fare  female  male  class_1  class_2  class_3\n",
              " 0    34.5      0      0    7.8292       0     1        0        0        1\n",
              " 1    47.0      1      0    7.0000       1     0        0        0        1\n",
              " 2    62.0      0      0    9.6875       0     1        0        1        0\n",
              " 3    27.0      0      0    8.6625       0     1        0        0        1\n",
              " 4    22.0      1      1   12.2875       1     0        0        0        1\n",
              " ..    ...    ...    ...       ...     ...   ...      ...      ...      ...\n",
              " 413   0.0      0      0    8.0500       0     1        0        0        1\n",
              " 414  39.0      0      0  108.9000       1     0        1        0        0\n",
              " 415  38.5      0      0    7.2500       0     1        0        0        1\n",
              " 416   0.0      0      0    8.0500       0     1        0        0        1\n",
              " 417   0.0      1      1   22.3583       0     1        0        0        1\n",
              " \n",
              " [418 rows x 9 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOgMvZ0Hbk81",
        "outputId": "c528792b-6c20-407c-e7c8-ce865e80062e"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05665483, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.07718194, 1.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.10181448, 0.        , 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.06322351, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFk3K5XLwld3",
        "outputId": "9b37ab98-9834-422c-deb1-c3e4521ea97a"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = tf.round(predictions)\n",
        "predictions = tf.squeeze(predictions)\n",
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([418])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWpTzDAW0lOX"
      },
      "source": [
        "d = {'PassengerId': [i for i in range(892,1310)], 'Survived' : predictions }\n",
        "df = pd.DataFrame(d)\n",
        "df.to_csv('predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}